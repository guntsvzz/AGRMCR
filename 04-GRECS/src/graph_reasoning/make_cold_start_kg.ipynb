{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Argument:\n",
    "    config = '../../config/beauty/graph_reasoning/UPGPR.json'\n",
    "    seed = 0\n",
    "    domain = 'Beauty'\n",
    "    preference = 'positive'\n",
    "\n",
    "# Example of creating an instance of the class with the default values\n",
    "args = Argument()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "from utils import *\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "\n",
    "with open(args.config, \"r\") as f:\n",
    "    config = edict(json.load(f))\n",
    "\n",
    "config.seed = args.seed\n",
    "# config.TRAIN_EMBEDS.epochs = args.epochs\n",
    "# config.TRAIN_EMBEDS.min_epochs = args.min_epochs\n",
    "\n",
    "transe_config = config.TRAIN_EMBEDS\n",
    "transe_config.use_user_relations = config.use_user_relations\n",
    "transe_config.use_entity_relations = config.use_entity_relations\n",
    "\n",
    "assert (\n",
    "    transe_config.min_epochs <= transe_config.epochs\n",
    "), \"Minimum number of epochs should be lower than total number of epochs.\"\n",
    "\n",
    "if config.use_wandb:\n",
    "    wandb.init(\n",
    "        project=config.wandb_project_name, name=config.wandb_run_name, config=config\n",
    "    )\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = transe_config.gpu\n",
    "\n",
    "transe_config.device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "set_name = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.processed_data_dir = '../../data/beauty/Amazon_Beauty_01_01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_cold_start_kg import InitalUserEmbedding, UserPreferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22363, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds[\"user\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embedding: ../../data/beauty/Amazon_Beauty_01_01/test_transe_embed.pkl\n"
     ]
    }
   ],
   "source": [
    "init_embed = InitalUserEmbedding(\n",
    "    set_name=set_name,\n",
    "    config=config\n",
    ")\n",
    "embeds = init_embed.embeds\n",
    "\n",
    "transe_config = config.TRAIN_EMBEDS\n",
    "\n",
    "# load cold start users\n",
    "cold_users_path = os.path.join(config.processed_data_dir, \"cold_start_users.json\")\n",
    "cold_users = json.load(open(cold_users_path, \"r\"))\n",
    "\n",
    "# load cold start items\n",
    "cold_items_path = os.path.join(config.processed_data_dir, \"cold_start_items.json\")\n",
    "cold_items = json.load(open(cold_items_path, \"r\"))\n",
    "\n",
    "# set all cold start users embeddings to 0\n",
    "tmp_cold_users = cold_users[\"test\"] + cold_users[\"validation\"]\n",
    "embeds[\"user\"][tmp_cold_users] = 0\n",
    "\n",
    "# # set all cold start items embeddings to 0\n",
    "# tmp_cold_items = cold_items[\"test\"] + cold_items[\"validation\"]\n",
    "# embeds[\"item\"][tmp_cold_items] = 0\n",
    "\n",
    "tmp_cold_users = cold_users[set_name]\n",
    "tmp_cold_items = cold_items[set_name]\n",
    "# making a copy of the embeddings to avoid using the modified cold start embeddings in the next iteration\n",
    "tmp_embeds = deepcopy(embeds)\n",
    "\n",
    "nb_relations = 0\n",
    "user_preferences = UserPreferences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_pref 2251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c493bc42c049efaf3fd84ded4cd102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2251 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cold_start_uids 2079\n"
     ]
    }
   ],
   "source": [
    "def load_user_pref(path, domain):\n",
    "    user_pref_path = os.path.join(path)\n",
    "    # Load JSON data from a file\n",
    "    user_pref = json.load(open(f'{user_pref_path}/user_preference_{domain}.json', 'r'))\n",
    "    return user_pref\n",
    "\n",
    "domain = args.domain\n",
    "user_pref = load_user_pref(config.processed_data_dir, domain)\n",
    "print('user_pref', len(user_pref))\n",
    "\n",
    "cold_start_uids = {}\n",
    "for idx in tqdm(range(len(user_pref))):\n",
    "    user_id = user_pref[str(idx)]['idx_user']\n",
    "    target_item = user_pref[str(idx)]['idx_item']\n",
    "    user_acc_feature = user_pref[str(idx)]['user_acc_feature']\n",
    "    user_rej_feature = user_pref[str(idx)]['user_rej_feature']\n",
    "    user_rej_items = user_pref[str(idx)]['user_rej_items']\n",
    "    \n",
    "    user_preferred = init_embed.user_preference_config(\n",
    "        user_acc_feature = user_acc_feature, \n",
    "        user_rej_feature = user_rej_feature, \n",
    "        user_rej_items = user_rej_items, \n",
    "    )\n",
    "    \n",
    "    user_key = user_pref[str(idx)]['idx_user']\n",
    "    if user_key in cold_start_uids:\n",
    "        for key, value in user_preferred.items():\n",
    "            if isinstance(value, list):\n",
    "                cold_start_uids[user_key][key].extend(value)\n",
    "                # Remove redundant values\n",
    "                cold_start_uids[user_key][key] = list(set(cold_start_uids[user_key][key]))\n",
    "    else:\n",
    "        cold_start_uids[user_key] = user_preferred\n",
    "\n",
    "print('cold_start_uids', len(cold_start_uids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Accessing items in the dictionary:\n",
    "# for idx, user in enumerate(cold_start_uids):\n",
    "#     # for relation, entity in dataset.data_args.item_relation.items():\n",
    "#     for relation, entity in user_preferences.items():\n",
    "#         # print(f'RELATION : {relation.ljust(16)} | ENTITY : {entity}')\n",
    "#         if relation == 'disinterested_in':\n",
    "#             relation = 'interested_in'\n",
    "#             continue\n",
    "#         entities = user_preferred[relation]\n",
    "#         all_related_emb = (\n",
    "#             embeds[entity[1]][entities] - embeds[relation][0]\n",
    "#         )\n",
    "#         nb_relations += all_related_emb.shape[0]\n",
    "#         # sum all related entities embeddings\n",
    "#         if relation in ['interested_in', 'like', 'dislike']:\n",
    "#             tmp_embeds[\"user\"][user] += all_related_emb.sum(axis=0)\n",
    "#         # elif relation in ['disinterested_in']:\n",
    "#         #     zero_embeds[\"user\"] -= all_related_emb.sum(axis=0)\n",
    "#     # divide by the number of relations to get the average\n",
    "#     if nb_relations > 0:\n",
    "#         tmp_embeds[\"user\"][user] /= nb_relations \n",
    "    \n",
    "# # save the embeddings\n",
    "# save_embed(\n",
    "#     config.processed_data_dir, f\"{set_name}_cold_start_transe_embed.pkl\", tmp_embeds\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7700074  0.7353711  0.75064622 0.7338551  0.80718175 0.77831027\n",
      " 0.79847464 0.73965569 0.7497185  0.73536031 0.81858419 0.76926914\n",
      " 0.79451204 0.76544339 0.73352902 0.81425411 0.72757791 0.78073842\n",
      " 0.71517224 0.7387626 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example vectors and matrix\n",
    "A = np.random.rand(100)\n",
    "B = np.random.rand(20, 100)  # n is 10 in this example\n",
    "# Normalize A\n",
    "A_norm = A / np.linalg.norm(A)\n",
    "# Normalize B\n",
    "B_norm = B / np.linalg.norm(B, axis=1)[:, np.newaxis]\n",
    "# Compute cosine similarity\n",
    "similarity = np.dot(B_norm, A_norm)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k maximum similarity indices: [14303  6842  7624  7128  8609  8178  4333  3354  4245  3406 16142  3703\n",
      " 10244  3624 16943 10652  1867  6799  9411  5805  8386 15607  2963 17509\n",
      "   236 10772   146  2218 18630 17511  9964    72   726 12140 14050 14695\n",
      " 14251 12646  5105  5518  3812 11910  9369  3125  3730  7912 11579  7839\n",
      "  4111  9958 12253 17350 13398  3372  3877 15618  2925 15193  1092 10013\n",
      "  5032 14283 11864 11622  4207  7641   249 15549  6663  8183 18045 14760\n",
      "  9454 16849  3017 19661 12483  1280  5500 14786 15624  4482 11573  2605\n",
      "  6755 13768 10410  8507 12758  2943  7058  5679  4980 19465 12571  9834\n",
      "  6236 14511  2399  3334 11024  6696  7551  4100  5678  5629  7707  1059\n",
      "  9408  3897 14926 12869 14124  9384  9890 19756 14203  7844 11823 17023\n",
      " 19326 12979 13333 14310  7948 10086  1009  3453 14879  7734  6398 14692\n",
      "  3749 13249  8760 15390  4406  3306  3789 11329 12771 13186  7348  5581\n",
      " 17469  2729 15072 13962 16735 19820 11876 10679 11993 17566 13672  3117\n",
      "  3889  2661  6865 18447  8171 16684 15852 10043  2478  5019  3199  2330\n",
      "  3346  8035  7910  9609 10132   885  6482 15295  3041  2972 19601  7730\n",
      "  9500  9800 10484 13269 18348 12969  6491 14062  7709 12690  4995 19129\n",
      "  7397 14802  8085 18015  2878 15389  4947 16238  6995 10809  2706  5172\n",
      "  8445 19110 15114  4309  9314 11254  6183 10501  7086 17623 10625  6985\n",
      "  6516 11487  2641  6958 11089 10275   468 14150  8204 11222  5617   457\n",
      "  9616  6573  3084 15108  1993 10660 18693  7152  8752    23 11675 13339\n",
      "  2872  6677  4872  3333  4003 19830 10630  1402  5318 10326 10765 12578\n",
      " 15598 13566 17970 17771  9067 19530  3055 12654   806  5269 15674 17853\n",
      "  2502 16099 17782  4317 13244  1254  1888 10805  5295 19264  8149  3524\n",
      "  1331 12961 10570   182 12946 16045 13841   852  1584 14751 12648  7900\n",
      " 17849 11630  9587 19249 13031 13721 14515 13718 14503 16649 19012 10800\n",
      " 17881 16189  1083 17241  1571  5498  9553 11040 13881  2715 13569  3391\n",
      "  7726 19464 17426 17267 14096   223 17658   264  7120 15149  3591  2909\n",
      " 19894   471 17755  4684 16007 10952  2310  3421 18062 15626  6523 16949\n",
      "  6073 14026 13499 18449  2563  8465 11797  9160 16818 16560  4757  7495\n",
      "  3664 14753   401  1020 12884 10256 11984   202 15860  8089 11565 15721\n",
      "  4724 19440  3669 10857  9724  2166 12914 17141 19958   710   341 13428\n",
      "  2333 11353  6377 10055  7613 10538 11771  7681 18914  8046   523  3458\n",
      " 16806  6378  1169  4307 17199 13283 16379 14322 16306  9899 18386  7849\n",
      " 14358  9793 16476 14158 17490  3793  4332 18165  3830 19490  8769  8227\n",
      "  4035 18402  8591 17235 15711 17135  6023 11102 15743  7505 19298   724\n",
      " 10468  2380 12715  8548 19358  4530 12147  2445 13128  4425 12904  6460\n",
      "  1541 13104 15589  6469  4568 11642   665 10310 15084 15655 15143  8881\n",
      "  1689  6066  3585 16220   635 15050  7688 16906 14715  9150  7130 18877\n",
      "  4056  6608  7169  6270  4420 14596  9686  4825  5293  8303  8887  7126\n",
      "  5886 14318  6314  2921 10362  3062  5276 13929 17636  3633 19943 17795\n",
      "  8568  4377  8119   211 14489  2091  1467 10714  3210  7883  1583 16450\n",
      "  9328   302 17696 17159 15596 14711 12347  8693 19914  2703  5409 13374\n",
      "  9673 19633 12777  6384  1603 10841  2933  2152  8699  1532 14342 19841\n",
      "  2099  3025 14431  2413 10548 10153  5130 15514  1863  9079 11191  9818\n",
      "  5214  2414  5820 12881 17936   204  8611 12617 19238 18095  8882 10698\n",
      "  9702  1932  7986 16173 18576 16767  7588  1988 19847  7620 12090  1097\n",
      " 11077 18300 13795 13781 15793 15623 13676 12581  7151 13725 19374  8008\n",
      " 13722 10613 14589 14057   850   290    73 18609  6718  2130 19157 18853\n",
      "  9668  8932 15315  5626 11196 16052 10300 16666 18625  3979 18839  9721\n",
      "  5520  3922 10018  2034  7187  5959  7432 10354  2066  4107  4681  7997\n",
      "   580 16329  9614 10739 10914  6927  7522   359 10402 12036 10532 12360\n",
      "  6899  9146 17330 15637  4104  5086  3310 12091 14195 17464 16064 18988\n",
      " 14744 14092 17099  9230 14800  9001 17186  8143 18779 12458  5645  7410\n",
      "  5715 19616  9273 12369 10431 15464  5349  5220 15435 17796 14101  8519\n",
      "    86 19572 18379 17059 14859 16417 14426 11095 13713 18403  6034  8488\n",
      "  4065  4031 15416 17202 17945 10868 15330  9544 16342  1179 16704 12685\n",
      " 19213 18398 10364  7184 10170  9512 14611 11793  1508   754 14559  7871\n",
      " 18703  7330 14113  9339 13954  5203  5800 19187  1633 19888 10879  9992\n",
      "  3303 18395 19284 19700 10826  3422  1241 11674  8588 16592 14457 15570\n",
      "  2785 18901 11474  2288  6595 12315  5902 15575 15375  6880  1768   618\n",
      " 10665 12426  1890   130 11303  1942  1099 12173 14365  2183  9215  2938\n",
      " 13497 11107 15164 14261  8270 12464  4446 16732 19848 16713 17533  9965\n",
      " 13863 19131  5093  5139  1255  7805  3001  6113 16915   890  8780 19383\n",
      " 14121 12132  2258  9306  9413  5697 19770 11495 15888   103  2950 11632\n",
      "  6216 14496 18387  8788 19579  7763 14864   460 19467 13681 13406 16540\n",
      " 14877 15388 12047 14445  7318  8073  7858  2336 11383 17418  7388 19252\n",
      " 17223  7683 18093  1471 18545 16870   136  3142 11804 10162  3502 10520\n",
      "  2960  5173 11106 18591  4097 11262 12075  5864 15782 18266 18369 16944\n",
      "  1050 19444 14351  2957 12549 11393 15438  7218  1011 18688  1345 15964\n",
      " 14258 19503  5399 19472 10697  5527 16661  7513  8615 12962  5836 19733\n",
      " 15406 18830  3628  6414  3010  9579  2965   186 18209 11146 16229 13534\n",
      " 10578  2987 17344  5995 16590  4586  2022 19920  8141  3813 13453  5331\n",
      " 15049   888   422  5752 11789 19542 12270  3829  3861 10131 13923 13814\n",
      "  5948 17513   482  4032  6476  6996  4263  7807 17933  3098  4789  9932\n",
      " 10580 14298  2195 11431  2021  3123  5637  6505  5917 17339  7237 17981\n",
      "  5153  4467  5021 11678 12508  7651 18585  2309 16491  7371  8268  4510\n",
      " 19746 16579 18019  5815  6881  1154   328  1401 13271  5496  4319   266\n",
      " 15521  3265  2690 19531 17399  8075  6213 12410 14833 18343  3808  4536\n",
      " 16170 14036  6121 13378  3634  3949 17476  3854  6410 11362  4588  5718\n",
      " 11264 19640  2147  9035 16292  8162  8226  1755  4076 11653 11743  8439\n",
      "  7381   227 10971  1859  2819  8207 15038  5146  5012  2876  7271 13964\n",
      "  2746 14004 14178 10949  7042  6360  1124 18219 10144 11230 19448 14179\n",
      "  6385  1429 17288  3275  7717 15595 15028 16981 10753  6301 18289  6351\n",
      " 14962  1730 14315 18240]\n",
      "Top-k minimum similarity indices: [  982  1034   504 10264 16248  7265 18959  6734  1623 15695 10175 16675\n",
      " 12156 12269 10194  4225 16366 18131  6522  6807  1737   679  4081 19178\n",
      " 19893 18295   417 19396  6707 19404  7159 15918 12415  1632  2297  6302\n",
      "  8038  2221  5913 17073  7775  3058 11800 12800 11747 17813 13844 15784\n",
      "  2432 17487  5525  3963  8335 11749  2007 12907  7935 16778 12436 16141\n",
      " 19631  2585 12945 14655  6487  9077  3900 16240 10862 14632  3282  5216\n",
      "  4927 12349  3144 16749 15493 17882 17926 17190  5213 12185  1023 16510\n",
      "  5784 14870 10503 12008 19954  9409  6610 12015  7654 17316 17549 17956\n",
      " 10505  4998  7277 12474 14595  7139 16901 10590  5066 10540 16168  3494\n",
      " 19617 18079   216 14552  2977  9043  1686 17934 16810 10338   200  4341\n",
      " 11926 15613 11437  5590 19485 16491 14691 11254 10037 14006  1973  9353\n",
      " 15579 15190 19520 17234 16498 19211   261  3476 15223  3378  7818 10855\n",
      "  4091  4212  6463  3612 17959 11828  4120  1216 10600 16582  4989  5576\n",
      "  1627 10749  2557 16795 15829 10205 15311 18852 18503  9017  8949 12102\n",
      " 19860 13437  6370 19259 15710 18090  9938  5195  1139 11629 17178 14705\n",
      " 11233  5211 14798 19459 17119 10355 16390 19936  4544  8294  3323  5951\n",
      "   673  9299 19341  5026  2206 13910 13847 17330  3733 13693    66 13544\n",
      "  2643 12695  9858 17356  4302 19758  7214  4806  9565  9225  9491  1735\n",
      "  7209  1179  4771   308 19619 19641 10210  9319  1570  8196  1260  9374\n",
      " 17416 12842  2094 12265 18434  2089  8296 12339 16659 11725  3822 17096\n",
      "  6980  7776 16674  8444 12117  6504  8059 17436 19933  6486 11278  9887\n",
      "  9669  6243  4200  6426  4572 11584  4440  6951  5697 10650  5938 13289\n",
      "  2402 17369 11940 18007 16764  5040 12775  5145  7705  5662  3184  4222\n",
      " 16339 16841  8541 13251 15387  2990 11585  7066 16844 12134 15576   588\n",
      " 11839  9127  7577 12437 16073 16009  3086 15058 13068  9186  8572   617\n",
      " 12478 19047   337 11764   288 11428  6116  9863  2855 13762 17311 18485\n",
      "  8315  6028  5447  1809  5443 17776  9888  5624    28  1889 18074  8909\n",
      "  6502  9167 12988 18908 18580 10826  6521 15715 11151  7843  6631 12524\n",
      " 12902  3077  5303  4953  4147  7663 12657  2937 19132 19359   239  7203\n",
      " 12208 19137 10623  6395 12746 13190  4272  8158  5459  5944  6987 12391\n",
      "  8709 15172 17680  9100 17810  4307 12650 18635  3465  1512 12407  1342\n",
      "   948   277 18734 12456  2490  7271 16979 14172 15018  8692 13392 13475\n",
      "  2485  1621  3118 14063   214  8616 10787  8022   494 17578 13165  6811\n",
      "  9596  4239  9860  5853 18550 17558  9967 16488 13526  6400 11306 12481\n",
      "  6031  4441  5899  4903 17083  1060 15373  5446 13489 14186 19261  5407\n",
      " 15899 12609  8273  3040 15870 15967  1897 15140 14490 10757 10874  5452\n",
      " 14840   372 10499  5358 12505   518  2049 17304  7210 16345  3747 10565\n",
      "  2421   703 12898   503 18426  2640 18243 13257  1943 18130 12860 17289\n",
      "  7886 15205  1664 16827 16043  2325  1499  2021 17955  4576  2054 16356\n",
      "  9377   555 19173 12619 19027 15558 11815 19630 15366  7848 15154 13139\n",
      " 13509 11215  4328 17858  8146  7789  7145 13110 11129 18606  8341  7093\n",
      " 11345  3734 10602 19454  9855  4689   217  9426   914 12703 13135 10961\n",
      "  9335  6496 12634  7742  4475  7191 12225 15234  2681  7992  1108 14865\n",
      "  6436 18824  8983 13494 17941 14059  8424 14355  8614 12680  5404  4770\n",
      " 15232  4326 15675  5082  9998 16487  5107 13680  6593   221 12882  2299\n",
      " 17324 14898 11070  4053  3433 14003   256 13932  7979 14292 14932  2638\n",
      "  6093  1204  9234  8398 18683 19478  1252 19054  9897  4340 12354 18492\n",
      "  2625  7169  4398  7947  6639   234 10657  3398  1193  1438  6579 12060\n",
      "  9712 16394  9432 17678 14709  7262 12828 12891  1203 17627  8322 18190\n",
      " 19764  2736 16393  8985  1568 15103  5398 11778 19770 17077 17592  2505\n",
      " 14257  1584 18924  7177   922  7200   205 16149 16544 14848  6423 11519\n",
      "  3856  6099 10982 11173 15745  7731 12278 11920  8813 10417  1856  9804\n",
      "  7279   498  1232 11443  6070  3737 11401  2510  8507 14892 13137 10367\n",
      "  7779 14669 19413 19647 19571  6004 10798  1454  3929  2618  6294  3756\n",
      "  2825 14399 18199  3835  1163 12074  7254 13559  9981 19926  1967 15268\n",
      "  4909 13136 15548 13928  8900  6845 11668  4560 19899 12159 14418   204\n",
      "  8803  8667 11616  9084 12097 13824  7444  5986 11320 13571  1227 18029\n",
      "  2498  9638 12937   602  2979 12137   633  1733  6258  8316  7055 16363\n",
      " 17014  1259 10756 11179 15423  6712 18565 14730 19006 14147  9297  3247\n",
      " 15077 15157 12069  9355 17688 12301 19479 15608 15799  9148   897  6484\n",
      " 18563 12930 11748  5759 16252  3228 14463  2657  9852  1293  6214 18764\n",
      "  4487 10471 17821 17090  3523 19220   409 10270 12056 11083 19967 11903\n",
      " 16982  4878 12176 10737 15859 12973 10094 12887 11483 17707 14148  6862\n",
      "  9904 18671 16837 17967 13918  4977   609   642 18027  5053 15740 17447\n",
      " 13170 15958 10459  7001 10425 10759  1600 18236  2126 12112 10016  8373\n",
      "   727 15798   344 13389 17540  9281 10286 15244  6203 19857 15848 12454\n",
      " 12659  2115  4638  8739  6654 18147  2897   556  2387 15985  1546  2616\n",
      "  6730  8551  6284 12298   629  5526  1979  4936 10628  5841  8346 12275\n",
      "  7796  1436  9480 14111  8144  1452 15165 13340   327 18170  8588 17701\n",
      " 18522 13322 12459  9755 14412  3611  9350  8277  3883 11174 13267 14028\n",
      " 17151  2096  7862  3543  7917  8200 12812  7762  4731  7702  8980 19125\n",
      " 18025 17830  5940   706 17961 17246 14646 15840 15470 15552  6107 13069\n",
      "  8971  7325 12667 10427  5408  8263  2620  8039  7393 18340  7413 18218\n",
      "  3815 10521  3129   627 13345 14826 14424  4166  4561 18478  8110 10815\n",
      "  7552 16522  5206  7920 16147  3310  7532  6335 18476  8836 14606 14547\n",
      "  4055 10489 11249  3544  2472  4594  1032  1455  3187  3513 17400 10109\n",
      "  5690   331 16470 12189   391  5651 11853 13978  6620   805  8378  3316\n",
      "  5431 18486 10077  4635  4845  7174  1087  8920 14998  5862  6650  4021\n",
      " 17485  9465  1794  2195 16642 15065  3216 12883  2332  1341  5947  8711\n",
      "   747  7812 16606 13245  9242 16217  5756  2675 16046 10422   932 10260\n",
      "  3643 18366  2326 16943 18817 11399  7073 14005 13744 15064  1109  2870\n",
      " 10981  5457 11819 12747 17092 18438 16434  8933 13895 11149  9227  3327\n",
      "  6451 12664 12911  1935  6503  3386 15734  6825 10659 13425  8854 19626\n",
      "  8268  7414  7329 12927]\n",
      "Overlapping indices: [  204  1179  1584  2021  2195  3310  4307  5697  7169  7271  8268  8507\n",
      "  8588 10826 11254 16491 16943 17330 19770]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def top_k_argmax(A, B, k):\n",
    "    # Normalize A\n",
    "    A_norm = A / np.linalg.norm(A)\n",
    "    # Normalize B\n",
    "    B_norm = B / np.linalg.norm(B, axis=1)[:, np.newaxis]\n",
    "    # Compute cosine similarity\n",
    "    similarity = np.dot(B_norm, A_norm)\n",
    "    # Get top-k argmax indices\n",
    "    top_k_max_indices = np.argpartition(similarity, -k)[-k:]\n",
    "    top_k_max_indices = top_k_max_indices[np.argsort(similarity[top_k_max_indices])[::-1]]\n",
    "    \n",
    "    # Get top-k max similarities\n",
    "    top_k_max_values = similarity[top_k_max_indices]\n",
    "\n",
    "    return top_k_max_indices, top_k_max_values\n",
    "\n",
    "def top_k_argmin(A, B, k):\n",
    "    # Normalize A\n",
    "    A_norm = A / np.linalg.norm(A)\n",
    "    # Normalize B\n",
    "    B_norm = B / np.linalg.norm(B, axis=1)[:, np.newaxis]\n",
    "    # Compute cosine similarity\n",
    "    similarity = np.dot(B_norm, A_norm)\n",
    "    # Get top-k argmin indices\n",
    "    top_k_min_indices = np.argpartition(similarity, k)[:k]\n",
    "    top_k_min_indices = top_k_min_indices[np.argsort(similarity[top_k_min_indices])]\n",
    "    \n",
    "    # Get top-k min similarities\n",
    "    top_k_min_values = similarity[top_k_min_indices]\n",
    "\n",
    "    return top_k_min_indices, top_k_min_values\n",
    "\n",
    "# Example usage\n",
    "A = np.random.rand(100)\n",
    "C = np.random.rand(100)\n",
    "B = np.random.rand(20000, 100)  # n is 30 in this example\n",
    "k = 1000\n",
    "\n",
    "top_k_max_indices, top_k_max_values = top_k_argmax(A, B, k)\n",
    "top_k_min_indices, top_k_min_values = top_k_argmin(C, B, k)\n",
    "\n",
    "# Find overlapping indices\n",
    "overlap_indices = np.intersect1d(top_k_max_indices, top_k_min_indices)\n",
    "\n",
    "print(\"Top-k maximum similarity indices:\", top_k_max_indices)\n",
    "# print(\"Top-k maximum similarity values:\", top_k_max_values)\n",
    "print(\"Top-k minimum similarity indices:\", top_k_min_indices)\n",
    "# print(\"Top-k minimum similarity values:\", top_k_min_values)\n",
    "print(\"Overlapping indices:\", overlap_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  204,  1179,  1584,  2021,  2195,  3310,  4307,  5697,  7169,\n",
       "        7271,  8268,  8507,  8588, 10826, 11254, 16491, 16943, 17330,\n",
       "       19770])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  204,  1179,  1584,  2021,  2195,  3310,  4307,  5697,  7169,\n",
       "        7271,  8268,  8507,  8588, 10826, 11254, 16491, 16943, 17330,\n",
       "       19770])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
